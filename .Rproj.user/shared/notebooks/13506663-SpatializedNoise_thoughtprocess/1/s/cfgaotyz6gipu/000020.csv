"0","library(here)"
"0","# Add noise level data"
"0","csv_directory='MorroBay Mar 2023 Noise Files'"
"0","csv_files <- list.files(path = csv_directory, pattern = ""*.csv"", full.names = TRUE)"
"0","dataframes_list <- list()"
"0",""
"0","# Loop through each CSV file load, change name"
"0","for (csv_file in csv_files) {"
"0","  # Read the CSV file"
"0","  df <- read.csv(csv_file, header = TRUE)"
"0","  "
"0","  # Extract the first and eighth columns"
"0","  df <- df[, c(""yyyy.mm.ddTHH.MM.SSZ"", 'TOL_16000')]"
"0","  colnames(df)<-c('UTC', 'NL')"
"0","  "
"0","  # Extract the first 10 characters from the filename"
"0","  file_name <- substr(basename(csv_file), 1, 10)"
"0","  "
"0","  # Create a 'DriftName' column with the extracted filename"
"0","  df$DriftName <- file_name"
"0","  "
"0","  # Append the dataframe to the list"
"0","  dataframes_list[[file_name]] <- df"
"0","}"
"0",""
"0","# Combine all dataframes into a single dataframe"
"0","noiseDf <- bind_rows(dataframes_list)"
"0","noiseDf$datetime_posix <- as.POSIXct(noiseDf$UTC, "
"0","                                     format = ""%Y-%m-%dT%H:%M:%OSZ"","
"0","                                     tz='UTC')"
"0",""
"0","for(drift in DriftNames){"
"0","  GPSsub = subset(GPSdf, DriftName == drift)"
"0","  NLsub =  subset(noiseDf, DriftName==drift)"
"0","  "
"0","  UTMflon <- approxfun(GPSsub$UTC, GPSsub$Longitude)"
"0","  UTMflat <- approxfun(GPSsub$UTC, GPSsub$Latitude)"
"0","  NLf<-approxfun(NLsub$datetime_posix, NLsub$NL, na.rm = TRUE)"
"0","  "
"0","  ##############################################################"
"0","  # Calculate the range from the whale to the GPS, TDOA and RL"
"0","  ############################################################"
"0","  "
"0","  # Lat/lon/ of the drift when the call was produced"
"0","  noiseDf$Lon[noiseDf$DriftName==drift] =UTMflon(NLsub$datetime_posix)"
"0","  noiseDf$Lat[noiseDf$DriftName==drift] = UTMflat(NLsub$datetime_posix)"
"0","  GPSdf$NL[GPSdf$DriftName==drift] <-NLf(GPSsub$UTC)"
"0","}"
"0",""
"0","colnames(noiseDf)[2]<-'NL'"
"0",""
"0","# Clear out any NA values"
"0","noiseDf = noiseDf[!is.na(noiseDf$Lat),]"
"0",""
"0","# add seconds since start as an integer for the gam"
"0","noiseDf$seconds = as.numeric(noiseDf$datetime_posix-median(noiseDf$datetime_posix))"
"0",""
"0","# there are some duplicated values for some reason."
"0","duplicatedIdx = which(duplicated(noiseDf$Lon))"
"0","noiseDf$Lon[duplicatedIdx]=noiseDf$Lon[duplicatedIdx]+"
"0","  rnorm(n = length(duplicatedIdx))/1000"
"0","noiseDf$Lat[duplicatedIdx]=noiseDf$Lat[duplicatedIdx]+"
"0","  rnorm(n = length(duplicatedIdx))/1000"
"0",""
"0","duplicatedIdx = which(duplicated(GPSdf$Lon))"
"0","GPSdf$Lon[duplicatedIdx]=GPSdf$Lon[duplicatedIdx]+"
"0","  rnorm(n = length(duplicatedIdx))/1000"
"0","GPSdf$Lat[duplicatedIdx]=GPSdf$Lat[duplicatedIdx]+"
"0","  rnorm(n = length(duplicatedIdx))/1000"
"0",""
"0","ggplot(GPSdf)+"
"0","  geom_point(aes(x=Lon, y=Lat, color=NL))+"
"0","  scale_color_viridis_c(option='plasma')"
